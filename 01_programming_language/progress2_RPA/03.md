### 2. 웹 스크래핑

#### 이론

웹 스크래핑은 웹 페이지의 데이터를 추출하는 기술입니다. Python에서는 `requests`와 `BeautifulSoup` 라이브러리를 사용하여 HTML을 파싱하고 데이터를 추출할 수 있습니다.

#### 실습

**HTML 파싱 및 데이터 추출**

```python
import requests
from bs4 import BeautifulSoup

url = 'https://example.com'
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

# 제목 추출
title = soup.find('title').text
print(title)
```

**API 호출**

```python
import requests

url = 'https://api.example.com/data'
response = requests.get(url)
data = response.json()

print(data)
```

#### 과제

- 웹 페이지에서 특정 데이터를 추출하고, 추출한 데이터를 CSV 파일로 저장하세요.

**해설**

1. 웹 페이지에서 데이터 추출
   ```python
   import requests
   from bs4 import BeautifulSoup

   url = 'https://example.com'
   response = requests.get(url)
   soup = BeautifulSoup(response.text, 'html.parser')

   # 예시: 모든 링크 추출
   links = soup.find_all('a')
   link_list = [{'text': link.text, 'href': link.get('href')} for link in links]
   ```

2. 추출한 데이터를 CSV 파일로 저장
   ```python
   import csv

   with open('links.csv', 'w', newline='') as csvfile:
       fieldnames = ['text', 'href']
       writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

       writer.writeheader()
       for link in link_list:
           writer.writerow(link)
   ```

